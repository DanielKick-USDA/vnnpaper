{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visible Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data ----\n",
    "from dataG2F.core import get_data\n",
    "from dataG2F.qol  import ensure_dir_path_exists\n",
    "\n",
    "# Data Utilities ----\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model Building  ----\n",
    "## General ====\n",
    "import torch\n",
    "from   torch import nn\n",
    "import torch.nn.functional as F\n",
    "from   torch.utils.data import Dataset\n",
    "from   torch.utils.data import DataLoader\n",
    "\n",
    "from vnnpaper.zma import \\\n",
    "    BigDataset,    \\\n",
    "    plDNN_general, \\\n",
    "    mask_parents,  \\\n",
    "    vnn_factory_1, \\\n",
    "    vnn_factory_2, \\\n",
    "    vnn_factory_3\n",
    "\n",
    "# Hyperparameter Tuning ----\n",
    "import os # needed for checking history (saved by lightning) \n",
    "\n",
    "## Logging with Pytorch Lightning ====\n",
    "import lightning.pytorch as pl\n",
    "from   lightning.pytorch.loggers import CSVLogger # used to save the history of each trial (used by ax)\n",
    "\n",
    "## Adaptive Experimentation Platform ====\n",
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "# from ax.utils.notebook.plotting import init_notebook_plotting, render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = '../nbs_artifacts/zma_g2f_yhat_02/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings ====\n",
    "run_hyps = 5 #75 \n",
    "run_hyps_force = False # should we run more trials even if the target number has been reached?\n",
    "max_hyps = 100\n",
    "\n",
    "# Run settings: \n",
    "params_run = {\n",
    "    'batch_size': 256, #256,\n",
    "    'max_epoch' : 2   #256,    \n",
    "}\n",
    "\n",
    "# data settings\n",
    "params_data = {\n",
    "    # 'y_var': 'Yield_Mg_ha',\n",
    "    'y_var': [\n",
    "        # Description quoted from competition data readme\n",
    "        'Yield_Mg_ha',     # Grain yield in Mg per ha at 15.5% grain moisture, using plot area without alley (Mg/ha).\n",
    "        'Pollen_DAP_days', # Number of days after planting that 50% of plants in the plot began shedding pollen.\n",
    "        'Silk_DAP_days',   # Number of days after planting that 50% of plants in the plot had visible silks.\n",
    "        'Plant_Height_cm', # Measured as the distance between the base of a plant and the ligule of the flag leaf (centimeter).\n",
    "        'Ear_Height_cm',   # Measured as the distance from the ground to the primary ear bearing node (centimeter).\n",
    "        'Grain_Moisture',  # Water content in grain at harvest (percentage).\n",
    "        'Twt_kg_m3'        # Shelled grain test weight (kg/m3), a measure of grain density.\n",
    "    ],\n",
    "\n",
    "    'y_resid': 'None', # None, Env, Geno\n",
    "    'y_resid_strat': 'None', # None, naive_mean, filter_mean, ...\n",
    "    'holdout_parents': [\n",
    "        ## 2022 ====\n",
    "        'LH244',\n",
    "        ## 2021 ====\n",
    "        'PHZ51',\n",
    "        # 'PHP02',\n",
    "        # 'PHK76',\n",
    "        ## 2019 ====\n",
    "        # 'PHT69',\n",
    "        'LH195',\n",
    "        ## 2017 ====\n",
    "        # 'PHW52',\n",
    "        # 'PHN82',\n",
    "        ## 2016 ====\n",
    "        # 'DK3IIH6',\n",
    "        ## 2015 ====\n",
    "        # 'PHB47',\n",
    "        # 'LH82',\n",
    "        ## 2014 ====\n",
    "        # 'LH198',\n",
    "        # 'LH185',\n",
    "        # 'PB80',\n",
    "        # 'CG102',\n",
    " ],    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [    \n",
    "    ## Output Size ====\n",
    "    {\n",
    "    'name': 'default_out_nodes_inp',\n",
    "    'type': 'range',\n",
    "    'bounds': [1, 8],\n",
    "    'value_type': 'int',\n",
    "    'log_scale': False\n",
    "    },\n",
    "    {\n",
    "    'name': 'default_out_nodes_edge',\n",
    "    'type': 'range',\n",
    "    'bounds': [1, 32],\n",
    "    'value_type': 'int',\n",
    "    'log_scale': False\n",
    "    },\n",
    "    {\n",
    "    'name': 'default_out_nodes_out',\n",
    "    'type': 'fixed',\n",
    "    'value': len(params_data['y_var']) if type(params_data['y_var']) == list else 1,\n",
    "    'value_type': 'int',\n",
    "    'log_scale': False\n",
    "    },\n",
    "    ## Dropout ====\n",
    "    {\n",
    "    'name': 'default_drop_nodes_inp',\n",
    "    'type': 'range',\n",
    "    'bounds': [0.01, 0.99],\n",
    "    'value_type': 'float',\n",
    "    'log_scale': False\n",
    "    },\n",
    "    {\n",
    "    'name': 'default_drop_nodes_edge',\n",
    "    'type': 'range',\n",
    "    'bounds': [0.01, 0.99],\n",
    "    'value_type': 'float',\n",
    "    'log_scale': False\n",
    "    },\n",
    "    {\n",
    "    'name': 'default_drop_nodes_out',\n",
    "    'type': 'range',\n",
    "    'bounds': [0.01, 0.99],\n",
    "    'value_type': 'float',\n",
    "    'log_scale': False,\n",
    "    'sort_values':True\n",
    "    },\n",
    "    ## Node Repeats ====\n",
    "    {\n",
    "    'name': 'default_reps_nodes_inp',\n",
    "    'type': 'choice',\n",
    "    'values': [1, 2, 3],\n",
    "    'value_type': 'int',\n",
    "    'is_ordered': True,\n",
    "    'sort_values':True\n",
    "    },\n",
    "    {\n",
    "    'name': 'default_reps_nodes_edge',\n",
    "    'type': 'choice',\n",
    "    'values': [1, 2, 3],\n",
    "    'value_type': 'int',\n",
    "    'is_ordered': True,\n",
    "    'sort_values':True\n",
    "    },\n",
    "    {\n",
    "    'name': 'default_reps_nodes_out',\n",
    "    'type': 'choice',\n",
    "    'values': [1, 2, 3],\n",
    "    'value_type': 'int',\n",
    "    'is_ordered': True,\n",
    "    'sort_values':True\n",
    "    },\n",
    "    ## Node Output Size Scaling ====\n",
    "    {\n",
    "    'name': 'default_decay_rate',\n",
    "    'type': 'choice',\n",
    "    'values': [0+(0.1*i) for i in range(10)]+[1.+(1*i) for i in range(11)],\n",
    "    'value_type': 'float',\n",
    "    'is_ordered': True,\n",
    "    'sort_values':True\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_log_dir = cache_path+\"lightning\"\n",
    "exp_name = [e for e in cache_path.split('/') if e != ''][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'default_out_nodes_out',\n",
       "  'type': 'fixed',\n",
       "  'value': 7,\n",
       "  'value_type': 'int',\n",
       "  'log_scale': False}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in params_list if e['name'] == 'default_out_nodes_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameterization is needed for setup. These values will be overwritten by Ax if tuning is occuring. \n",
    "# in this file I define params later. I've included it here to gurantee that we can merge other params dicts into it.\n",
    "params = {\n",
    "'default_out_nodes_inp'  : 1,\n",
    "'default_out_nodes_edge' : 1,\n",
    "'default_out_nodes_out'  : len(params_data['y_var']) if type(params_data['y_var']) == list else 1,\n",
    "\n",
    "'default_drop_nodes_inp' : 0.0,\n",
    "'default_drop_nodes_edge': 0.0,\n",
    "'default_drop_nodes_out' : 0.0,\n",
    "\n",
    "'default_reps_nodes_inp' : 1,\n",
    "'default_reps_nodes_edge': 1,\n",
    "'default_reps_nodes_out' : 1,\n",
    "\n",
    "'default_decay_rate'     : 1\n",
    "}\n",
    "\n",
    "default_out_nodes_inp  = params['default_out_nodes_inp' ]\n",
    "default_out_nodes_edge = params['default_out_nodes_edge'] \n",
    "default_out_nodes_out  = params['default_out_nodes_out' ]\n",
    "\n",
    "default_drop_nodes_inp = params['default_drop_nodes_inp' ] \n",
    "default_drop_nodes_edge= params['default_drop_nodes_edge'] \n",
    "default_drop_nodes_out = params['default_drop_nodes_out' ] \n",
    "\n",
    "default_reps_nodes_inp = params['default_reps_nodes_inp' ]\n",
    "default_reps_nodes_edge= params['default_reps_nodes_edge']\n",
    "default_reps_nodes_out = params['default_reps_nodes_out' ]\n",
    "\n",
    "default_decay_rate = params['default_decay_rate' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " [{'name': 'default_out_nodes_out',\n",
       "   'type': 'fixed',\n",
       "   'value': 7,\n",
       "   'value_type': 'int',\n",
       "   'log_scale': False}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_out_nodes_out, [e for e in params_list if e['name'] == 'default_out_nodes_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = params_run['batch_size']\n",
    "max_epoch  = params_run['max_epoch']\n",
    "\n",
    "y_var = params_data['y_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prefix = [e for e in cache_path.split('/') if e != ''][-1]\n",
    "\n",
    "if 'None' != params_data['y_resid_strat']:\n",
    "    save_prefix = save_prefix+'_'+params_data['y_resid_strat']\n",
    "\n",
    "ensure_dir_path_exists(dir_path = cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "use_gpu_num = 0\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if use_gpu_num in [0, 1]: \n",
    "    torch.cuda.set_device(use_gpu_num)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep ----\n",
    "obs_geno_lookup          = get_data('obs_geno_lookup')\n",
    "phno                     = get_data('phno')\n",
    "ACGT_gene_slice_list     = get_data('KEGG_slices')\n",
    "parsed_kegg_gene_entries = get_data('KEGG_entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the given y variable is there\n",
    "# single column version\n",
    "# phno = phno.loc[(phno[y_var].notna()), ].copy()\n",
    "# phno = phno.reset_index().drop(columns='index')\n",
    "\n",
    "# multicolumn\n",
    "# mask based on the y variables\n",
    "na_array = phno[y_var].isna().to_numpy().sum(axis=1)\n",
    "mask_no_na = list(0 == na_array)\n",
    "\n",
    "phno = phno.loc[mask_no_na, ].copy()\n",
    "phno = phno.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update obs_geno_lookup\n",
    "\n",
    "tmp = phno.reset_index().rename(columns={'index': 'Phno_Idx_new'}).loc[:, ['Phno_Idx_new', 'Geno_Idx']]\n",
    "tmp = pd.merge(tmp,\n",
    "          tmp.drop(columns='Phno_Idx_new').drop_duplicates().reset_index().rename(columns={'index': 'Phno_Idx_Orig_new'}))\n",
    "tmp = tmp.sort_values('Phno_Idx_new').reset_index(drop=True)\n",
    "\n",
    "obs_geno_lookup = tmp.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make holdout sets\n",
    "holdout_parents = params_data['holdout_parents']\n",
    "\n",
    "# create a mask for parent genotype\n",
    "mask = mask_parents(df= phno, col_name= 'Hybrid', holdout_parents= holdout_parents)\n",
    "\n",
    "train_mask = mask.sum(axis=1) == 0\n",
    "test_mask  = mask.sum(axis=1) > 0\n",
    "\n",
    "train_idx = train_mask.loc[train_mask].index\n",
    "test_idx  = test_mask.loc[test_mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y to residual if needed\n",
    "\n",
    "if params_data['y_resid'] == 'None':\n",
    "    pass\n",
    "else:\n",
    "    if params_data['y_resid_strat'] == 'naive_mean':\n",
    "        # use only data in the training set (especially since testers will be more likely to be found across envs)\n",
    "        # get enviromental means, subtract from observed value\n",
    "        tmp = phno.loc[train_idx, ]\n",
    "        env_mean = tmp.groupby(['Env_Idx']\n",
    "                     ).agg(Env_Mean = (y_var, 'mean')\n",
    "                     ).reset_index()\n",
    "        tmp = phno.merge(env_mean)\n",
    "        tmp.loc[:, y_var] = tmp.loc[:, y_var] - tmp.loc[:, 'Env_Mean']\n",
    "        phno = tmp.drop(columns='Env_Mean')\n",
    "\n",
    "    if params_data['y_resid_strat'] == 'filter_mean':\n",
    "        # for adjusting to environment we could use _all_ observations but ideally we will use the same set of genotypes across all observations\n",
    "        def minimum_hybrids_for_env(tmp = phno.loc[:, ['Env', 'Year', 'Hybrid']],\n",
    "                                    year = 2014):\n",
    "            # Within each year what hybrids are most common?\n",
    "            tmp = tmp.loc[(tmp.Year == year), ].groupby(['Env', 'Hybrid']).count().reset_index().sort_values('Year')\n",
    "\n",
    "            all_envs = set(tmp.Env)\n",
    "            # if we filter on the number of sites a hybrid is planted at, what is the largest number of sites we can ask for before we lose a location?\n",
    "            # site counts for sets which contain all envs\n",
    "            i = max([i for i in list(set(tmp.Year)) if len(set(tmp.loc[(tmp.Year >= i), 'Env'])) == len(all_envs)])\n",
    "\n",
    "            before = len(set(tmp.loc[:, 'Hybrid']))\n",
    "            after  = len(set(tmp.loc[(tmp.Year >= i), 'Hybrid']))\n",
    "            print(f'Reducing {year} hybrids from {before} to {after} ({round(100*after/before)}%).')\n",
    "            tmp = tmp.loc[(tmp.Year >= i), ['Env', 'Hybrid']].reset_index(drop=True)\n",
    "            return tmp\n",
    "\n",
    "\n",
    "        tmp = phno.loc[:, ['Env', 'Year', 'Hybrid']]\n",
    "        filter_hybrids = [minimum_hybrids_for_env(tmp = phno.loc[:, ['Env', 'Year', 'Hybrid']], year = i) \n",
    "                          for i in list(set(phno.Year)) ]\n",
    "        env_mean = pd.concat(filter_hybrids).merge(phno, how = 'left')\n",
    "\n",
    "        env_mean = env_mean.groupby(['Env_Idx']\n",
    "                          ).agg(Env_Mean = (y_var, 'mean')\n",
    "                          ).reset_index()\n",
    "\n",
    "        tmp = phno.merge(env_mean)\n",
    "        tmp.loc[:, y_var] = tmp.loc[:, y_var] - tmp.loc[:, 'Env_Mean']\n",
    "        phno = tmp.drop(columns='Env_Mean')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center and y value data\n",
    "assert 0 == phno.loc[:, y_var].isna().sum().sum() # second sum is for multiple y_vars\n",
    "\n",
    "y = phno.loc[:, y_var].to_numpy() # added to make multiple ys work\n",
    "# use train index to prevent information leakage\n",
    "y_c = y[train_idx].mean(axis=0)\n",
    "y_s = y[train_idx].std(axis=0)\n",
    "\n",
    "y = (y - y_c)/y_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Using VNNHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default_out_nodes_inp': 1,\n",
       " 'default_out_nodes_edge': 1,\n",
       " 'default_out_nodes_out': 7,\n",
       " 'default_drop_nodes_inp': 0.0,\n",
       " 'default_drop_nodes_edge': 0.0,\n",
       " 'default_drop_nodes_out': 0.0,\n",
       " 'default_reps_nodes_inp': 1,\n",
       " 'default_reps_nodes_edge': 1,\n",
       " 'default_reps_nodes_out': 1,\n",
       " 'default_decay_rate': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_out_nodes_out, [e for e in params_list if e['name'] == 'default_out_nodes_out'], params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "{'default_out_nodes_inp': 1, 'default_out_nodes_edge': 1, 'default_out_nodes_out': 7, 'default_drop_nodes_inp': 0.0, 'default_drop_nodes_edge': 0.0, 'default_drop_nodes_out': 0.0, 'default_reps_nodes_inp': 1, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 1, 'default_decay_rate': 1}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    }
   ],
   "source": [
    "myvnn, new_lookup_dict = vnn_factory_1(parsed_kegg_gene_entries = parsed_kegg_gene_entries, params = params, ACGT_gene_slice_list = ACGT_gene_slice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " [{'name': 'default_out_nodes_out',\n",
       "   'type': 'fixed',\n",
       "   'value': 7,\n",
       "   'value_type': 'int',\n",
       "   'log_scale': False}],\n",
       " 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_out_nodes_out, [e for e in params_list if e['name'] == 'default_out_nodes_out'], params['default_out_nodes_out']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate nodes membership in each matrix and positions within each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Structured Matrices for Layers\n",
    "M_list = vnn_factory_2(vnn_helper = myvnn, node_to_inp_num_dict = new_lookup_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_hat': {'size': tensor(7, dtype=torch.int32),\n",
       "  'stop': tensor(7),\n",
       "  'start': tensor(0)}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_out_nodes_out, [e for e in params_list if e['name'] == 'default_out_nodes_out'], params['default_out_nodes_out']\n",
    "M_list[-1].col_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dataloader using `M_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = new_lookup_dict\n",
    "\n",
    "vals = get_data('KEGG_slices')\n",
    "vals = [torch.from_numpy(e).to(torch.float) for e in vals]\n",
    "# restrict to the tensors that will be used\n",
    "vals = torch.concat([vals[lookup_dict[i]].reshape(4926, -1) \n",
    "                     for i in M_list[0].row_inp\n",
    "                    #  for i in dd[0]['inp'] # matches\n",
    "                     ], axis = 1)\n",
    "\n",
    "vals = vals.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = False,\n",
    "    lookup_obs  = torch.from_numpy(np.array(train_idx)), #X.get('val:train',       ops_string='   asarray from_numpy      '),\n",
    "    lookup_geno = torch.from_numpy(obs_geno_lookup),\n",
    "    y =           torch.from_numpy(y).to(torch.float32)[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True \n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(BigDataset(\n",
    "    lookups_are_filtered = False,\n",
    "    lookup_obs  = torch.from_numpy(np.array(test_idx)), #X.get('val:train',       ops_string='   asarray from_numpy      '),\n",
    "    lookup_geno = torch.from_numpy(obs_geno_lookup),\n",
    "    y =           torch.from_numpy(y).to(torch.float32)[:, None],\n",
    "    G =           vals,\n",
    "    G_type = 'raw',\n",
    "    send_batch_to_gpu = 'cuda:0'\n",
    "    ),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_list):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer_list = nn.ModuleList(layer_list)\n",
    " \n",
    "    def forward(self, x):\n",
    "        for l in self.layer_list:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny Test Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " [{'name': 'default_out_nodes_out',\n",
       "   'type': 'fixed',\n",
       "   'value': 7,\n",
       "   'value_type': 'int',\n",
       "   'log_scale': False}],\n",
       " 7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_out_nodes_out, [e for e in params_list if e['name'] == 'default_out_nodes_out'], params['default_out_nodes_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "{'default_out_nodes_inp': 1, 'default_out_nodes_edge': 1, 'default_out_nodes_out': 7, 'default_drop_nodes_inp': 0.0, 'default_drop_nodes_edge': 0.0, 'default_drop_nodes_out': 0.0, 'default_reps_nodes_inp': 1, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 1, 'default_decay_rate': 1}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layer_list): ModuleList(\n",
       "    (0): SparseLinearCustom(\n",
       "      in_features=144468, out_features=6067, bias=True, sparsity=0.00016482610845557937, connectivity=tensor([[     0,      0,      0,  ...,   6066,   6066,   6066],\n",
       "              [     0,      1,      2,  ..., 144465, 144466, 144467]]), small_world=False\n",
       "    )\n",
       "    (1): SparseLinearCustom(\n",
       "      in_features=6067, out_features=2210, bias=True, sparsity=0.0015673396693185522, connectivity=tensor([[   0,    1,    1,  ..., 2207, 2208, 2209],\n",
       "              [  14,   22,   36,  ..., 3885,  488, 3914]]), small_world=False\n",
       "    )\n",
       "    (2): SparseLinearCustom(\n",
       "      in_features=2210, out_features=552, bias=True, sparsity=0.0018501213194307823, connectivity=tensor([[   0,    1,    2,  ...,  549,  550,  551],\n",
       "              [   0,    1,    4,  ..., 1361, 2038, 1491]]), small_world=False\n",
       "    )\n",
       "    (3): SparseLinearCustom(\n",
       "      in_features=552, out_features=232, bias=True, sparsity=0.004427473763118441, connectivity=tensor([[  0,   0,   0,  ..., 229, 230, 231],\n",
       "              [  5, 479, 493,  ..., 271, 104, 443]]), small_world=False\n",
       "    )\n",
       "    (4): SparseLinearCustom(\n",
       "      in_features=232, out_features=131, bias=True, sparsity=0.007633587786259542, connectivity=tensor([[  0,   0,   0,   1,   1,   1,   1,   2,   2,   2,   2,   3,   3,   4,\n",
       "                 4,   4,   4,   4,   4,   4,   5,   5,   5,   5,   6,   6,   6,   6,\n",
       "                 6,   6,   7,   7,   7,   7,   7,   7,   8,   8,   8,   8,   9,   9,\n",
       "                10,  10,  10,  10,  10,  10,  10,  10,  10,  11,  11,  11,  11,  11,\n",
       "                11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  12,\n",
       "                12,  12,  12,  12,  12,  13,  13,  13,  13,  13,  14,  14,  14,  14,\n",
       "                14,  14,  14,  14,  14,  15,  16,  16,  17,  17,  18,  19,  19,  20,\n",
       "                20,  20,  20,  21,  21,  21,  21,  21,  22,  22,  22,  22,  22,  22,\n",
       "                22,  22,  23,  23,  23,  23,  23,  24,  24,  24,  24,  24,  24,  24,\n",
       "                25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "                39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "                53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "                67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
       "                81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "                95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
       "               109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
       "               123, 124, 125, 126, 127, 128, 129, 130],\n",
       "              [  0, 149, 230,   1, 175, 193, 194,   2,   3, 179, 217,   4, 160,   5,\n",
       "                 6,  10,  18,  35,  38,  49,  50, 143, 180, 229,  31,  33,  46,  47,\n",
       "                55,  56,   7,  19,  28,  54,  64,  67,  40, 173, 202, 207,  23,  68,\n",
       "                 9,  13,  22,  25,  58,  62,  66,  74,  76,  11,  15,  24,  26,  27,\n",
       "                29,  30,  37,  45,  51,  52,  57,  63,  69,  72,  77,  78,  79,  71,\n",
       "               216, 219, 222, 225, 227,  12,  14,  34,  48,  85,  16,  21,  53,  59,\n",
       "                65,  80,  81,  82,  87,  88,  91, 100, 104, 212, 108,  90, 109,  98,\n",
       "               150, 197, 226,  93,  96,  99, 116, 117,  97, 101, 103, 105, 110, 111,\n",
       "               115, 118,  94, 102, 113, 121, 161, 106, 107, 119, 120, 122, 123, 124,\n",
       "               144,  43, 145, 146,   8, 147, 148,  17, 151, 142, 135, 152, 153,  70,\n",
       "               154, 139, 155, 156, 125,  20, 157, 158, 159, 129, 132, 162, 163, 164,\n",
       "               165, 166, 167, 168, 169, 170, 171, 172,  41, 174, 176, 177, 178, 140,\n",
       "               114, 134, 137, 181,  61,  84, 182, 138, 184, 183, 186, 185, 187, 188,\n",
       "                36,  75, 189, 190, 191, 192, 195, 196, 198, 131,  42, 199, 200,  92,\n",
       "               201, 203, 141, 204,  73, 205, 128,  44, 206,  60, 112, 208, 209, 210,\n",
       "               130,  86, 211,  32, 213,  39, 214, 215, 127, 218, 220,  95, 221, 126,\n",
       "               223, 224,  89,  83, 136, 133, 228, 231]]), small_world=False\n",
       "    )\n",
       "    (5): SparseLinearCustom(\n",
       "      in_features=131, out_features=63, bias=True, sparsity=0.017327032594208168, connectivity=tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "                 0,   0,   0,   0,   0,   0,   1,   1,   2,   2,   2,   2,   2,   2,\n",
       "                 2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "                 2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "                 2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   3,\n",
       "                 4,   4,   4,   5,   5,   5,   6,   6,   6,   6,   6,   7,   7,   7,\n",
       "                 7,   7,   7,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,\n",
       "                18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
       "                32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
       "                46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
       "                60,  61,  62],\n",
       "              [  1,   2,  29,  38,  42,  44,  45,  55,  56,  57,  58,  59,  86,  92,\n",
       "               114, 115, 116, 118, 121, 129,   3,  61,   0,   1,   2,  26,  27,  31,\n",
       "                32,  33,  38,  39,  45,  55,  56,  58,  59,  60,  62,  63,  64,  70,\n",
       "                71,  72,  73,  75,  77,  80,  81,  82,  83,  84,  86,  87,  91,  93,\n",
       "                95,  96,  99, 102, 104, 106, 110, 112, 115, 118, 123, 126, 129,   8,\n",
       "                 9,  94,  98,   5,  67, 120,  12,  36,  37,  53, 105,   4,   6,   7,\n",
       "                10,  11,  13,  14,  25, 108,  50, 109,  19,  85, 130,  28,  51, 111,\n",
       "               113,  30,  52,  23,  20,  54,  88,  17, 117,  89,  21,  90,  34, 119,\n",
       "                35,  15, 122,  49,  40, 124,  41, 125,  43,  22, 127,  65,  97, 128,\n",
       "                66,  68,  69,  46,  18,  47, 100, 101, 103,  48,  74,  76,  24,  16,\n",
       "               107,  78,  79]]), small_world=False\n",
       "    )\n",
       "    (6): SparseLinearCustom(\n",
       "      in_features=63, out_features=68, bias=True, sparsity=0.018207282913165267, connectivity=tensor([[ 0,  0,  1,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  7,  7,  8,  8,\n",
       "                9,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
       "               26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "               44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
       "               62, 63, 64, 65, 66, 67],\n",
       "              [ 0,  2,  0,  2, 39,  0,  2,  0,  2,  0,  2,  1, 24,  2,  0,  2,  0,  2,\n",
       "                0,  2,  8,  9, 10, 11, 12, 13, 15,  7, 16, 17, 18, 19, 20, 21, 22,  5,\n",
       "               23, 25,  4, 26, 27, 28, 29, 30, 31, 32, 60, 33, 34, 62, 36, 37, 38, 40,\n",
       "               41, 42, 43,  3, 44, 46, 47, 48, 45, 50, 49, 51, 52, 53, 54, 55, 56, 57,\n",
       "               58, 59, 14,  6, 61, 35]]), small_world=False\n",
       "    )\n",
       "    (7): SparseLinearCustom(\n",
       "      in_features=68, out_features=7, bias=True, sparsity=1.0, connectivity=tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "                0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "                0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "                0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,\n",
       "                1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "                1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "                1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "                1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "                2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "                2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "                2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "                2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "                3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "                3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "                3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "                3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "                4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "                4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "                4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
       "                5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "                5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "                5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "                5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,\n",
       "                6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "                6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "                6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "                6,  6,  6,  6,  6,  6,  6,  6],\n",
       "              [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "               18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "               36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "               54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,  0,  1,  2,  3,\n",
       "                4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "               22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
       "               40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
       "               58, 59, 60, 61, 62, 63, 64, 65, 66, 67,  0,  1,  2,  3,  4,  5,  6,  7,\n",
       "                8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
       "               26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "               44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61,\n",
       "               62, 63, 64, 65, 66, 67,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,\n",
       "               12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
       "               30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "               48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65,\n",
       "               66, 67,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "               16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "               34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "               52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,  0,  1,\n",
       "                2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "               20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "               38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
       "               56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,  0,  1,  2,  3,  4,  5,\n",
       "                6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
       "               24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
       "               42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
       "               60, 61, 62, 63, 64, 65, 66, 67]]), small_world=False\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myvnn, new_lookup_dict = vnn_factory_1(parsed_kegg_gene_entries = parsed_kegg_gene_entries, params = params, ACGT_gene_slice_list = ACGT_gene_slice_list)\n",
    "M_list = vnn_factory_2(vnn_helper = myvnn, node_to_inp_num_dict = new_lookup_dict)\n",
    "layer_list =  vnn_factory_3(M_list = M_list)\n",
    "model = NeuralNetwork(layer_list = layer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 7])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer_list[-1]\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "model(next(iter(training_dataloader))[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 891 M \n",
      "---------------------------------------\n",
      "178 K     Trainable params\n",
      "891 M     Non-trainable params\n",
      "891 M     Total params\n",
      "3,565.936 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88131a96ff7242a2ace91c8c35c90c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2848051e3c479c8b19a5673b736691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([92, 1, 7])) that is different to the input size (torch.Size([92, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dea0cf159c64fccaa32656cf72f397f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([196, 1, 7])) that is different to the input size (torch.Size([196, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbe2b5dd71b472f91ddba1840ee32f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VNN = plDNN_general(model)  \n",
    "optimizer = VNN.configure_optimizers()\n",
    "trainer = pl.Trainer(max_epochs=max_epoch)\n",
    "trainer.fit(model=VNN, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VNN.mod\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "model(next(iter(training_dataloader))[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(parameterization):\n",
    "    myvnn, new_lookup_dict = vnn_factory_1(parsed_kegg_gene_entries = parsed_kegg_gene_entries, params = parameterization, ACGT_gene_slice_list = ACGT_gene_slice_list)\n",
    "    M_list = vnn_factory_2(vnn_helper = myvnn, node_to_inp_num_dict = new_lookup_dict)\n",
    "    layer_list =  vnn_factory_3(M_list = M_list)\n",
    "    model = NeuralNetwork(layer_list = layer_list)\n",
    "    \n",
    "    VNN = plDNN_general(model)  \n",
    "    optimizer = VNN.configure_optimizers()\n",
    "    logger = CSVLogger(lightning_log_dir, name=exp_name)\n",
    "    logger.log_hyperparams(params={\n",
    "        'params': parameterization\n",
    "    })\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=max_epoch, logger=logger)\n",
    "    trainer.fit(model=VNN, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)\n",
    "\n",
    "\n",
    "    # if we were optimizing number of training epochs this would be an effective loss to use.\n",
    "    # trainer.callback_metrics['train_loss']\n",
    "    # float(trainer.callback_metrics['train_loss'])\n",
    "\n",
    "    # To potentially _overtrain_ models and still let the selction be based on their best possible performance,\n",
    "    # I'll use the lowest average error in an epoch\n",
    "    log_path = lightning_log_dir+'/'+exp_name\n",
    "    fls = os.listdir(log_path)\n",
    "    nums = [int(e.split('_')[-1]) for e in fls] \n",
    "\n",
    "    M = pd.read_csv(log_path+f\"/version_{max(nums)}/metrics.csv\")\n",
    "    M = M.loc[:, ['epoch', 'train_loss']].dropna()\n",
    "\n",
    "    M = M.groupby('epoch').agg(\n",
    "        train_loss = ('train_loss', 'mean'),\n",
    "        train_loss_sd = ('train_loss', 'std'),\n",
    "        ).reset_index()\n",
    "\n",
    "    train_metric = M.train_loss.min()\n",
    "    print(train_metric)\n",
    "    return {\"train_loss\": (train_metric, 0.0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'default_out_nodes_out',\n",
       "  'type': 'fixed',\n",
       "  'value': 7,\n",
       "  'value_type': 'int',\n",
       "  'log_scale': False}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in params_list if e['name'] == 'default_out_nodes_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ax_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ax_client\u001b[38;5;241m.\u001b[39mget_next_trial()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ax_client' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-29 14:37:50] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 05-29 14:37:50] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='default_out_nodes_inp', parameter_type=INT, range=[1, 8]), RangeParameter(name='default_out_nodes_edge', parameter_type=INT, range=[1, 32]), FixedParameter(name='default_out_nodes_out', parameter_type=INT, value=7), RangeParameter(name='default_drop_nodes_inp', parameter_type=FLOAT, range=[0.01, 0.99]), RangeParameter(name='default_drop_nodes_edge', parameter_type=FLOAT, range=[0.01, 0.99]), RangeParameter(name='default_drop_nodes_out', parameter_type=FLOAT, range=[0.01, 0.99]), ChoiceParameter(name='default_reps_nodes_inp', parameter_type=INT, values=[1, 2, 3], is_ordered=True, sort_values=True), ChoiceParameter(name='default_reps_nodes_edge', parameter_type=INT, values=[1, 2, 3], is_ordered=True, sort_values=True), ChoiceParameter(name='default_reps_nodes_out', parameter_type=INT, values=[1, 2, 3], is_ordered=True, sort_values=True), ChoiceParameter(name='default_decay_rate', parameter_type=FLOAT, values=[0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0], is_ordered=True, sort_values=True)], parameter_constraints=[]).\n",
      "[INFO 05-29 14:37:50] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.\n",
      "[INFO 05-29 14:37:50] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=9 num_trials=None use_batch_trials=False\n",
      "[INFO 05-29 14:37:50] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=18\n",
      "[INFO 05-29 14:37:50] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=18\n",
      "[INFO 05-29 14:37:50] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 05-29 14:37:50] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 18 trials, BoTorch for subsequent trials]). Iterations after 18 will take longer to generate due to model-fitting.\n",
      "[INFO 05-29 14:37:50] ax.service.ax_client: Generated new trial 0 with parameters {'default_out_nodes_inp': 5, 'default_out_nodes_edge': 15, 'default_drop_nodes_inp': 0.032444, 'default_drop_nodes_edge': 0.686969, 'default_drop_nodes_out': 0.733806, 'default_reps_nodes_inp': 1, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 1, 'default_decay_rate': 0.4, 'default_out_nodes_out': 7} using model Sobol.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'default_out_nodes_inp': 5,\n",
       "  'default_out_nodes_edge': 15,\n",
       "  'default_drop_nodes_inp': 0.032444334886968136,\n",
       "  'default_drop_nodes_edge': 0.6869694077968598,\n",
       "  'default_drop_nodes_out': 0.7338055264949799,\n",
       "  'default_reps_nodes_inp': 1,\n",
       "  'default_reps_nodes_edge': 1,\n",
       "  'default_reps_nodes_out': 1,\n",
       "  'default_decay_rate': 0.4,\n",
       "  'default_out_nodes_out': 7},\n",
       " 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generated variables ====\n",
    "json_path = f\"./{lightning_log_dir}/{exp_name}.json\"\n",
    "\n",
    "loaded_json = False\n",
    "if os.path.exists(json_path): \n",
    "    ax_client = (AxClient.load_from_json_file(filepath = json_path))\n",
    "    loaded_json = True\n",
    "\n",
    "else:\n",
    "    ax_client = AxClient()\n",
    "    ax_client.create_experiment(\n",
    "        name=exp_name,\n",
    "        parameters=params_list,\n",
    "        objectives={\"train_loss\": ObjectiveProperties(minimize=True)}\n",
    "    )\n",
    "ax_client.get_next_trial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 05-29 14:37:53] ax.service.ax_client: Generated new trial 1 with parameters {'default_out_nodes_inp': 5, 'default_out_nodes_edge': 25, 'default_drop_nodes_inp': 0.28752, 'default_drop_nodes_edge': 0.268042, 'default_drop_nodes_out': 0.421013, 'default_reps_nodes_inp': 1, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 3, 'default_decay_rate': 5.0, 'default_out_nodes_out': 7} using model Sobol.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "{'default_out_nodes_inp': 5, 'default_out_nodes_edge': 25, 'default_drop_nodes_inp': 0.2875195280648768, 'default_drop_nodes_edge': 0.2680421245843172, 'default_drop_nodes_out': 0.4210134438984096, 'default_reps_nodes_inp': 1, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 3, 'default_decay_rate': 5.0, 'default_out_nodes_out': 7}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 895 M \n",
      "---------------------------------------\n",
      "188 K     Trainable params\n",
      "894 M     Non-trainable params\n",
      "895 M     Total params\n",
      "3,580.639 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1eecbb4c79b4d2aaaaa00113f921511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fc6e765cf4467b9bc507177ed198e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([92, 1, 7])) that is different to the input size (torch.Size([92, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489ff1dd8c4c400ab99e1f06e79948ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([196, 1, 7])) that is different to the input size (torch.Size([196, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b839fa0344a64bafa4f353d8190a2e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[INFO 05-29 14:38:34] ax.service.ax_client: Completed trial 1 with data: {'train_loss': (0.948367, 0.0)}.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/ax/core/data.py:286: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return cls(df=pd.concat(dfs, axis=0, sort=True))\n",
      "[INFO 05-29 14:38:34] ax.service.ax_client: Generated new trial 2 with parameters {'default_out_nodes_inp': 2, 'default_out_nodes_edge': 26, 'default_drop_nodes_inp': 0.780218, 'default_drop_nodes_edge': 0.600491, 'default_drop_nodes_out': 0.509896, 'default_reps_nodes_inp': 3, 'default_reps_nodes_edge': 3, 'default_reps_nodes_out': 2, 'default_decay_rate': 0.9, 'default_out_nodes_out': 7} using model Sobol.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9483667612075807\n",
      "################################################################################\n",
      "{'default_out_nodes_inp': 2, 'default_out_nodes_edge': 26, 'default_drop_nodes_inp': 0.780218251850456, 'default_drop_nodes_edge': 0.6004913296550513, 'default_drop_nodes_out': 0.5098963896185158, 'default_reps_nodes_inp': 3, 'default_reps_nodes_edge': 3, 'default_reps_nodes_out': 2, 'default_decay_rate': 0.9, 'default_out_nodes_out': 7}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 1.4 B \n",
      "---------------------------------------\n",
      "727 K     Trainable params\n",
      "1.4 B     Non-trainable params\n",
      "1.4 B     Total params\n",
      "5,708.917 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5980083e34564cb5a4b213eb418b4f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af893817c6243d28ac06d2c56f4963d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([92, 1, 7])) that is different to the input size (torch.Size([92, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ba33b1ac1b4efbbf54fd7a54ce4273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([196, 1, 7])) that is different to the input size (torch.Size([196, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2009d854b44b4a08898abc102a8715e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[INFO 05-29 14:40:20] ax.service.ax_client: Completed trial 2 with data: {'train_loss': (0.918986, 0.0)}.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/ax/core/data.py:286: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return cls(df=pd.concat(dfs, axis=0, sort=True))\n",
      "[INFO 05-29 14:40:20] ax.service.ax_client: Generated new trial 3 with parameters {'default_out_nodes_inp': 6, 'default_out_nodes_edge': 15, 'default_drop_nodes_inp': 0.767855, 'default_drop_nodes_edge': 0.770493, 'default_drop_nodes_out': 0.61511, 'default_reps_nodes_inp': 2, 'default_reps_nodes_edge': 3, 'default_reps_nodes_out': 3, 'default_decay_rate': 5.0, 'default_out_nodes_out': 7} using model Sobol.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9189858883619308\n",
      "################################################################################\n",
      "{'default_out_nodes_inp': 6, 'default_out_nodes_edge': 15, 'default_drop_nodes_inp': 0.767854532469064, 'default_drop_nodes_edge': 0.7704929233901202, 'default_drop_nodes_out': 0.6151102536171674, 'default_reps_nodes_inp': 2, 'default_reps_nodes_edge': 3, 'default_reps_nodes_out': 3, 'default_decay_rate': 5.0, 'default_out_nodes_out': 7}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 939 M \n",
      "---------------------------------------\n",
      "206 K     Trainable params\n",
      "939 M     Non-trainable params\n",
      "939 M     Total params\n",
      "3,757.914 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c9dae857314dd68a9765ed406768fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6b5a8ef00a4fdab3f0becb82297a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([92, 1, 7])) that is different to the input size (torch.Size([92, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c12db9b8b7472c882fae15addcb6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([196, 1, 7])) that is different to the input size (torch.Size([196, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d15c391576f48f39f0faddd42e20e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[INFO 05-29 14:41:32] ax.service.ax_client: Completed trial 3 with data: {'train_loss': (0.948679, 0.0)}.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/ax/core/data.py:286: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return cls(df=pd.concat(dfs, axis=0, sort=True))\n",
      "[INFO 05-29 14:41:32] ax.service.ax_client: Generated new trial 4 with parameters {'default_out_nodes_inp': 2, 'default_out_nodes_edge': 9, 'default_drop_nodes_inp': 0.37219, 'default_drop_nodes_edge': 0.960643, 'default_drop_nodes_out': 0.700118, 'default_reps_nodes_inp': 2, 'default_reps_nodes_edge': 3, 'default_reps_nodes_out': 1, 'default_decay_rate': 5.0, 'default_out_nodes_out': 7} using model Sobol.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9486792683601379\n",
      "################################################################################\n",
      "{'default_out_nodes_inp': 2, 'default_out_nodes_edge': 9, 'default_drop_nodes_inp': 0.3721903510577977, 'default_drop_nodes_edge': 0.9606425076536834, 'default_drop_nodes_out': 0.7001180348917841, 'default_reps_nodes_inp': 2, 'default_reps_nodes_edge': 3, 'default_reps_nodes_out': 1, 'default_decay_rate': 5.0, 'default_out_nodes_out': 7}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 939 M \n",
      "---------------------------------------\n",
      "206 K     Trainable params\n",
      "939 M     Non-trainable params\n",
      "939 M     Total params\n",
      "3,757.913 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48a2bfda9c34016a969406b452c17c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffd9f1b8bfa4314a3489e2c946df5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([92, 1, 7])) that is different to the input size (torch.Size([92, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d949983aa1846ff8f00787aeb51a104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([196, 1, 7])) that is different to the input size (torch.Size([196, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce846a206b9a41e7b3b98e12922cff7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[INFO 05-29 14:43:00] ax.service.ax_client: Completed trial 4 with data: {'train_loss': (0.965614, 0.0)}.\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/ax/core/data.py:286: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return cls(df=pd.concat(dfs, axis=0, sort=True))\n",
      "[INFO 05-29 14:43:00] ax.service.ax_client: Generated new trial 5 with parameters {'default_out_nodes_inp': 6, 'default_out_nodes_edge': 20, 'default_drop_nodes_inp': 0.751608, 'default_drop_nodes_edge': 0.761277, 'default_drop_nodes_out': 0.368766, 'default_reps_nodes_inp': 2, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 2, 'default_decay_rate': 11.0, 'default_out_nodes_out': 7} using model Sobol.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9656141996383667\n",
      "################################################################################\n",
      "{'default_out_nodes_inp': 6, 'default_out_nodes_edge': 20, 'default_drop_nodes_inp': 0.7516078797727823, 'default_drop_nodes_edge': 0.7612773055955767, 'default_drop_nodes_out': 0.3687657134979963, 'default_reps_nodes_inp': 2, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 2, 'default_decay_rate': 11.0, 'default_out_nodes_out': 7}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 928 M \n",
      "---------------------------------------\n",
      "191 K     Trainable params\n",
      "928 M     Non-trainable params\n",
      "928 M     Total params\n",
      "3,714.284 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff838526afd42d0afb728517b130c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ade6cdec4294dccaec4180364f171f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([92, 1, 7])) that is different to the input size (torch.Size([92, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b662ac1a32f454fabcf5e12be6a880b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([196, 1, 7])) that is different to the input size (torch.Size([196, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98608c6b2dc454a9a6e2c1f687fea2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "[INFO 05-29 14:43:46] ax.service.ax_client: Completed trial 5 with data: {'train_loss': (0.939915, 0.0)}.\n",
      "[INFO 05-29 14:43:46] ax.service.ax_client: Saved JSON-serialized state of optimization to `./../nbs_artifacts/zma_g2f_yhat_02/lightning/zma_g2f_yhat_02.json`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939914807677269\n"
     ]
    }
   ],
   "source": [
    "run_trials_bool = True\n",
    "if run_hyps_force == False:\n",
    "    if loaded_json: \n",
    "        # check if we've reached the max number of hyperparamters combinations to test\n",
    "        if max_hyps <= (ax_client.generation_strategy.trials_as_df.index.max()+1):\n",
    "            run_trials_bool = False\n",
    "\n",
    "if run_trials_bool:\n",
    "    # run the trials\n",
    "    for i in range(run_hyps):\n",
    "        parameterization, trial_index = ax_client.get_next_trial()\n",
    "        # Local evaluation here can be replaced with deployment to external system.\n",
    "        ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameterization))\n",
    "\n",
    "    ax_client.save_to_json_file(filepath = json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/ax/core/data.py:286: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return cls(df=pd.concat(dfs, axis=0, sort=True))\n",
      "[INFO 05-29 14:44:25] ax.service.ax_client: Generated new trial 6 with parameters {'default_out_nodes_inp': 6, 'default_out_nodes_edge': 16, 'default_drop_nodes_inp': 0.410168, 'default_drop_nodes_edge': 0.292775, 'default_drop_nodes_out': 0.841535, 'default_reps_nodes_inp': 1, 'default_reps_nodes_edge': 1, 'default_reps_nodes_out': 2, 'default_decay_rate': 7.0, 'default_out_nodes_out': 7} using model Sobol.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'default_out_nodes_inp': 6,\n",
       "  'default_out_nodes_edge': 16,\n",
       "  'default_drop_nodes_inp': 0.41016806114465,\n",
       "  'default_drop_nodes_edge': 0.29277470091357827,\n",
       "  'default_drop_nodes_out': 0.8415345510095358,\n",
       "  'default_reps_nodes_inp': 1,\n",
       "  'default_reps_nodes_edge': 1,\n",
       "  'default_reps_nodes_out': 2,\n",
       "  'default_decay_rate': 7.0,\n",
       "  'default_out_nodes_out': 7},\n",
       " 6)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax_client.get_next_trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Generated variables ====\n",
    "# json_path = f\"./{lightning_log_dir}/{exp_name}.json\"\n",
    "\n",
    "# loaded_json = False\n",
    "# if os.path.exists(json_path): \n",
    "#     ax_client = (AxClient.load_from_json_file(filepath = json_path))\n",
    "#     loaded_json = True\n",
    "\n",
    "# else:\n",
    "#     ax_client = AxClient()\n",
    "#     ax_client.create_experiment(\n",
    "#         name=exp_name,\n",
    "#         parameters=params_list,\n",
    "#         objectives={\"train_loss\": ObjectiveProperties(minimize=True)}\n",
    "#     )\n",
    "\n",
    "# run_trials_bool = True\n",
    "# if run_hyps_force == False:\n",
    "#     if loaded_json: \n",
    "#         # check if we've reached the max number of hyperparamters combinations to test\n",
    "#         if max_hyps <= (ax_client.generation_strategy.trials_as_df.index.max()+1):\n",
    "#             run_trials_bool = False\n",
    "\n",
    "# if run_trials_bool:\n",
    "#     # run the trials\n",
    "#     for i in range(run_hyps):\n",
    "#         parameterization, trial_index = ax_client.get_next_trial()\n",
    "#         # Local evaluation here can be replaced with deployment to external system.\n",
    "#         ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameterization))\n",
    "\n",
    "#     ax_client.save_to_json_file(filepath = json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/ax/core/data.py:286: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return cls(df=pd.concat(dfs, axis=0, sort=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "{'default_out_nodes_inp': 2, 'default_out_nodes_edge': 26, 'default_drop_nodes_inp': 0.780218251850456, 'default_drop_nodes_edge': 0.6004913296550513, 'default_drop_nodes_out': 0.5098963896185158, 'default_reps_nodes_inp': 3, 'default_reps_nodes_edge': 3, 'default_reps_nodes_out': 2, 'default_decay_rate': 0.9, 'default_out_nodes_out': 7}\n",
      "################################################################################\n",
      "Retaining 43.53%, 6067/13939 Entries\n",
      "Removed node \"Others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/kickd/miniconda3/envs/fastai/lib/python3.11/si ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type          | Params\n",
      "---------------------------------------\n",
      "0 | mod  | NeuralNetwork | 1.4 B \n",
      "---------------------------------------\n",
      "727 K     Trainable params\n",
      "1.4 B     Non-trainable params\n",
      "1.4 B     Total params\n",
      "5,708.917 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de836c316394754bd05107b9d64a47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/miniconda3/envs/fastai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58431527dfde49bea17402dfc28ce6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([256, 1, 7])) that is different to the input size (torch.Size([256, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n",
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:240: UserWarning: Using a target size (torch.Size([92, 1, 7])) that is different to the input size (torch.Size([92, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bc8859664244ca833f1341ad786804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kickd/Documents/vnnpaper/vnnpaper/zma.py:255: UserWarning: Using a target size (torch.Size([196, 1, 7])) that is different to the input size (torch.Size([196, 7])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(pred, y_i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0edb5151b94486182698a95b2305184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "parameterization = ax_client.get_best_parameters()[0]\n",
    "\n",
    "myvnn, new_lookup_dict = vnn_factory_1(parsed_kegg_gene_entries = parsed_kegg_gene_entries, params = parameterization, ACGT_gene_slice_list = ACGT_gene_slice_list)\n",
    "M_list = vnn_factory_2(vnn_helper = myvnn, node_to_inp_num_dict = new_lookup_dict)\n",
    "layer_list =  vnn_factory_3(M_list = M_list)\n",
    "model = NeuralNetwork(layer_list = layer_list)\n",
    "\n",
    "VNN = plDNN_general(model)  \n",
    "optimizer = VNN.configure_optimizers()\n",
    "# logger = CSVLogger(lightning_log_dir, name=exp_name)\n",
    "# logger.log_hyperparams(params={\n",
    "#     'params': parameterization\n",
    "# })\n",
    "\n",
    "# trainer = pl.Trainer(max_epochs=max_epoch, logger=logger)\n",
    "trainer = pl.Trainer(max_epochs=max_epoch)\n",
    "trainer.fit(model=VNN, train_dataloaders=training_dataloader, val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e.shape for e in next(iter(training_dataloader))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 7])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VNN.mod\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "model(next(iter(training_dataloader))[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
